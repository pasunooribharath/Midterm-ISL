# Chapter 4 Applied Problem 13:
install.packages("ISLR")
install.packages("ISLR2")
library(ISLR2)
library(MASS)
library(MASS)
library(class)
data(Weekly)
str(Weekly)
q()
# Chapter 4 Applied Problem 13:
install.packages("ISLR")
install.packages("ISLR2")
library(ISLR2)
library(MASS)
library(class)
data(Weekly)
str(Weekly)
summary(Weekly)
pairs(Weekly)
cor(Weekly[, -9])
attach(Weekly)
plot(Year, Volume)
plot(Volume)
glm.fits <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data=Weekly, family="binomial")
summary(glm.fits)
glm.probs = predict(glm.fits, Weekly, type = "response")
glm.pred = rep("Down", 1089)
glm.pred[glm.probs > .5] = "Up"
table(glm.pred, Weekly$Direction)
mean(glm.pred == Weekly$Direction)
train=(Year<2009)
Weekly.2009= Weekly[!train ,]
dim(Weekly.2009)
glm.fit = glm(Direction ~ Lag2, data = Weekly, subset = train, family = "binomial")
summary(glm.fit)
glm.probs = predict(glm.fit, Weekly.2009, type = "response")
glm.pred = rep("Down", 104)
glm.pred[glm.probs > 0.5] = "Up"
table(glm.pred, Weekly.2009$Direction)
mean(glm.pred == Weekly.2009$Direction)
mean(Weekly[!train, ]$Direction == "Up")
#e) Repeat (d) using LDA.
library(MASS)
lda.fit = lda(Direction ~ Lag2, data = Weekly, subset = train)
lda.fit
plot(lda.fit)
lda.pred = predict(lda.fit, Weekly.2009)
names(lda.pred)
lda.class=lda.pred$class
table(lda.class ,Weekly.2009$Direction)
mean(lda.class == Weekly.2009$Direction)
#f) Repeat (d) using QDA.
qda.fit = qda(Direction ~ Lag2, data = Weekly, subset = train)
qda.fit
qda.class=predict(qda.fit ,Weekly.2009)$class
table(qda.class ,Weekly.2009$Direction)
mean(qda.class==Weekly.2009$Direction)
library(class)
train.X = cbind(Weekly[train, ]$Lag2)
test.X = cbind(Weekly.2009$Lag2)
train.Direction = Weekly[train, ]$Direction
set.seed(1)
knn.pred = knn(train.X, test.X, train.Direction, k = 1)
table(knn.pred, Weekly.2009$Direction)
mean(knn.pred == Weekly.2009$Direction)
#h) Repeat (d) using naive Bayes.
install.packages('e1071', dependencies=TRUE)
library(e1071)
NB.fits <- naiveBayes(Direction ~ Lag2, data = Weekly, subset = train)
NB.preds <- predict(NB.fits, Weekly.2009)
table(NB.preds, Weekly.2009$Direction)
mean(NB.preds == Weekly.2009$Direction)
install.packages("ISLR")
install.packages("ISLR2")
install.packages("ISLR2")
install.packages("boot")
library(ISLR)
head(Default)
set.seed(1)
glm.fit <- glm(default ~ income + balance, data = Default, family = "binomial")
summary(glm.fit)
# I will use a 75-25 split when dividing my data into a training set and a validation set.
train <- sample(dim(Default)[1], 0.75*dim(Default)[1])
# ii) Fit a multiple logistic regression model using only the training observations.
glm.fit <- glm(default ~ income + balance, data = Default, subset = train, family = "binomial")
summary(glm.fit)
glm.probs <- predict(glm.fit, Default[-train, ], type = "response")
glm.preds <- rep("No", dim(Default)[1])
glm.preds[glm.probs > 0.5] = "Yes"
# iV) Compute the validation set error, which is the fraction of the observations in the validation set that are misclassified.
mean(glm.preds != Default[-train, "default"])
#split 1
train <- sample(dim(Default)[1], 0.75*dim(Default)[1])
glm.fit <- glm(default ~ income + balance, data = Default, subset = train, family = "binomial")
glm.probs <- predict(glm.fit, Default[-train, ], type = "response")
glm.preds <- rep("No", dim(Default)[1])
glm.preds[glm.probs > 0.5] <- "Yes"
mean(glm.preds != Default[-train, "default"])
# split 2
train <- sample(dim(Default)[1], 0.75*dim(Default)[1])
glm.fit <- glm(default ~ income + balance, data = Default, subset = train, family = "binomial")
glm.probs <- predict(glm.fit, Default[-train, ], type = "response")
glm.preds <- rep("No", dim(Default)[1])
glm.preds[glm.probs > 0.5] <- "Yes"
mean(glm.preds != Default[-train, "default"])
# split 3
train <- sample(dim(Default)[1], 0.75*dim(Default)[1])
glm.fit <- glm(default ~ income + balance, data = Default, subset = train, family = "binomial")
glm.probs <- predict(glm.fit, Default[-train, ], type = "response")
glm.preds <- rep("No", dim(Default)[1])
glm.preds[glm.probs > 0.5] <- "Yes"
mean(glm.preds != Default[-train, "default"])
1 - mean(Default[-train, "default"] == "No")
train <- sample(dim(Default)[1], dim(Default)[1] / 2)
glm.fit<- glm(default ~ income + balance + student, data = Default, family = "binomial", subset = train)
glm.probs <- predict(glm.fit, newdata = Default[-train, ], type = "response")
glm.pred <- rep("No", length(glm.probs))
glm.pred[glm.probs > 0.5] <- "Yes"
mean(glm.pred != Default[-train, ]$default)
library(ISLR)
set.seed(1)
attach(Default)
head(Default)
glm.fit <- glm(default ~ income + balance, data = Default, family = "binomial")
summary(glm.fit)
boot.fn = function(data, index){
coefs = coef(glm(default ~ income + balance, data = data, subset = index,
family = "binomial"))[c("income", "balance")]
return(coefs)
}
library(boot)
boot(Default, boot.fn, 1000)
library(ISLR2)
attach(Boston)
head(Boston)
mu.hat <- mean(medv)
mu.hat
se.hat <- sd(medv) / sqrt(dim(Boston)[1])
se.hat
library(boot)
set.seed(1)
boot.fn <- function(data, index) {
mu <- mean(data[index])
return (mu)
}
bstrap = boot(medv, boot.fn, 1000)
bstrap
t.test(medv)
CI.mu.hat <- c(bstrap$t0 - 2 * 0.4119, bstrap$t0 + 2 * 0.4119)
CI.mu.hat
med.hat <- median(medv)
med.hat
boot.fn <- function(data, index) {
mu <- median(data[index])
return (mu)
}
boot(medv, boot.fn, 1000)
medv.tenthperc = quantile(medv, c(0.1))
medv.tenthperc
boot.fn <- function(data, index) {
mu <- quantile(data[index], c(0.1))
return (mu)
}
boot(medv, boot.fn, 1000)
